{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# saranya's version \n",
    "import os\n",
    "import torch\n",
    "# %%\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "all_malwares = [\"Adialer.C\", \"Allaple.L\", \"C2LOP.gen!g\", \"Dontovo.A\", \"Lolyda.AA1\", \"Lolyda.AT\", \"Rbot!gen\",\n",
    "                \"Swizzor.gen!I\", \"Yuner.A\",\n",
    "                \"Agent.FYI\", \"Alueron.gen!J\", \"C2LOP.P\", \"Fakerean\", \"Lolyda.AA2\", \"Malex.gen!J\", \"Skintrim.N\", \"VB.AT\",\n",
    "                \"Allaple.A\", \"Autorun.K\", \"Dialplatform.B\", \"Instantaccess\", \"Lolyda.AA3\", \"Obfuscator.AD\", \"Swizzor.gen!E\",\n",
    "                \"Wintrim.BX\"]\n",
    "\n",
    "all_malwares_str_to_int = {val: key for key, val in enumerate(all_malwares)}\n",
    "# %%\n",
    "\n",
    "parent_path = '/data/saranyav/malimg_gnn/exe_files/'\n",
    "\n",
    "executed_npy_files_with_labels = dict()\n",
    "for malware_name in all_malwares:\n",
    "    path = parent_path + malware_name + '/'\n",
    "    dire = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "\n",
    "    for d in dire:\n",
    "        if d.endswith(\".npz\"):\n",
    "            executed_npy_files_with_labels[path + d] = malware_name\n",
    "\n",
    "\n",
    "# %%\n",
    "def filter_labels_with_k_samples(executed_npy_files_with_labels, all_malwares_str_to_int, k=100):\n",
    "    '''This function returns the labels for which we have at least k graphs with non-empty edges.'''\n",
    "    dataset = []\n",
    "    dataset_labels = {key: 0 for key, _ in all_malwares_str_to_int.items()}\n",
    "    count = 0\n",
    "    for sample_file in executed_npy_files_with_labels:\n",
    "        malware_name = executed_npy_files_with_labels[sample_file]\n",
    "        graph = torch.LongTensor(np.load(sample_file)['arr_0'])\n",
    "        if graph.shape[-1] == 0:\n",
    "            continue  # skip graph without edges\n",
    "        sparse_label = all_malwares_str_to_int[malware_name]\n",
    "\n",
    "        dataset_labels[malware_name] += 1\n",
    "    labels = []\n",
    "    for key in dataset_labels.keys():\n",
    "        if dataset_labels[key] > k:\n",
    "            labels.append(key)\n",
    "\n",
    "    return labels, dataset_labels\n",
    "\n",
    "\n",
    "def build_graph_dataset(label_names, executed_npy_files_with_labels, per_class_number=200, test_split=0.2):\n",
    "    '''This function builds the train and test sets with a given number of samples for each class.'''\n",
    "    label_names = set(label_names)\n",
    "    label_names_to_index = {key: i for i, key in enumerate(label_names)}\n",
    "    label_names_to_train_counts = {key: 0 for key in label_names}\n",
    "    label_names_to_test_counts = {key: 0 for key in label_names}\n",
    "    train_samples = per_class_number * (1 - test_split)\n",
    "    test_samples = per_class_number * test_split\n",
    "\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    for sample_file in executed_npy_files_with_labels:\n",
    "        malware_name = executed_npy_files_with_labels[sample_file]\n",
    "        if malware_name in label_names:\n",
    "            graph = torch.LongTensor(np.load(sample_file)['arr_0'])\n",
    "            if graph.shape[-1] > 0:\n",
    "                # we fill up the training set first\n",
    "                if label_names_to_train_counts[malware_name] < train_samples:\n",
    "                    data = Data(edge_index=graph)\n",
    "                    data.x = torch.normal(0, 1, size=(data.num_nodes, 10))  # for now we use random noise for the node\n",
    "                    sparse_label = label_names_to_index[malware_name]\n",
    "                    data.y = torch.tensor(sparse_label)\n",
    "                    train.append(data)\n",
    "\n",
    "                    label_names_to_train_counts[malware_name] += 1\n",
    "\n",
    "                elif label_names_to_test_counts[malware_name] < test_samples:\n",
    "                    data = Data(edge_index=graph)\n",
    "                    data.x = torch.normal(0, 1, size=(data.num_nodes, 10))  # for now we use random noise for the node\n",
    "                    sparse_label = label_names_to_index[malware_name]\n",
    "                    data.y = torch.tensor(sparse_label)\n",
    "                    test.append(data)\n",
    "\n",
    "                    label_names_to_test_counts[malware_name] += 1\n",
    "\n",
    "    return train, test, label_names_to_index, label_names_to_train_counts, label_names_to_test_counts\n",
    "\n",
    "\n",
    "# %%\n",
    "label_names, dataset_labels = filter_labels_with_k_samples(executed_npy_files_with_labels, all_malwares_str_to_int, k=100)\n",
    "# %%\n",
    "print(len(label_names[:-3]))\n",
    "train, test, label_names_to_index, label_names_to_train_counts, label_names_to_test_counts = build_graph_dataset(\n",
    "    label_names[:-3], executed_npy_files_with_labels, per_class_number=100, test_split=0.1)\n",
    "# %%\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "tr_loader = DataLoader(train, batch_size=1)\n",
    "te_loader = DataLoader(test, batch_size=1)\n",
    "# %%\n",
    "torch.save(tr_loader, 'imgmalware18_tr_loader.pth')\n",
    "torch.save(te_loader, 'imgmalware18_te_loader.pth')\n",
    "\n",
    "\n",
    "print(len(label_names[-3:]))\n",
    "train, test, label_names_to_index, label_names_to_train_counts, label_names_to_test_counts = build_graph_dataset(\n",
    "    label_names[-3:], executed_npy_files_with_labels, per_class_number=100, test_split=1)\n",
    "# %%\n",
    "print(len(train), len(test))\n",
    "\n",
    "te_loader = DataLoader(test, batch_size=1)\n",
    "# %%\n",
    "torch.save(te_loader, 'new_family_imgmalware3_te_loader.pth')\n",
    "\n",
    "\n",
    "# %%\n",
    "tr_loader_ = torch.load('imgmalware18_tr_loader.pth')\n",
    "te_loader_ = torch.load('imgmalware18_te_loader.pth')\n",
    "# %%\n",
    "data = test[100]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
