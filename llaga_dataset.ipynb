{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'exe_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m model \u001b[38;5;241m=\u001b[39m GCN(num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, hidden_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Load and process data\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m graphs, labels, input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mload_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# DataLoader\u001b[39;00m\n\u001b[1;32m     83\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(graphs, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mload_graphs\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m     48\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     49\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     51\u001b[0m     class_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, label)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(class_path):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'exe_files'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, BatchNorm, Linear\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.batch1 = BatchNorm(hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels * 4)\n",
    "        self.batch2 = BatchNorm(hidden_channels * 4)\n",
    "        self.conv3 = GCNConv(hidden_channels * 4, hidden_channels * 8)\n",
    "        self.batch3 = BatchNorm(hidden_channels * 8)\n",
    "        self.conv4 = GCNConv(hidden_channels * 8, hidden_channels)\n",
    "        self.batch4 = BatchNorm(hidden_channels)\n",
    "        self.conv5 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.batch5 = BatchNorm(hidden_channels)\n",
    "        self.conv6 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.batch1(x)\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.batch3(x)\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = self.batch4(x)\n",
    "        x = self.conv5(x, edge_index).relu()\n",
    "        x = self.batch5(x)\n",
    "        x = self.conv6(x, edge_index)\n",
    "        return x.mean(dim=0)\n",
    "\n",
    "def parse_cfg_to_edge_list(filepath):\n",
    "    edge_list = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            if \"->\" in line:  # Assuming edges are represented as 'source -> target'\n",
    "                source, target = line.strip().split('->')\n",
    "                edge_list.append([int(source.strip()), int(target.strip())])\n",
    "    return np.array(edge_list).T\n",
    "\n",
    "def load_graphs(base_path):\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    input_ids = []\n",
    "    for label in os.listdir(base_path):\n",
    "        class_path = os.path.join(base_path, label)\n",
    "        if os.path.isdir(class_path):\n",
    "            for file in os.listdir(class_path):\n",
    "                if file.endswith('.exe_cfg'):\n",
    "                    input_id = file.split('.')[0]\n",
    "                    edge_index = parse_cfg_to_edge_list(os.path.join(class_path, file))\n",
    "                    x = torch.ones((edge_index.max() + 1, 10))  # Assuming 10 features per node\n",
    "                    data = Data(x=x, edge_index=torch.tensor(edge_index, dtype=torch.long))\n",
    "                    dataset.append(data)\n",
    "                    labels.append(label)\n",
    "                    input_ids.append(input_id)\n",
    "    return dataset, labels, input_ids\n",
    "\n",
    "def get_embeddings(loader, model, device):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "        embeddings.append(out.cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Setup\n",
    "base_path = '/data/saranyav/malimg_gnn/exe_files/'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(num_features=10, hidden_channels=64).to(device)\n",
    "\n",
    "# Load and process data\n",
    "graphs, labels, input_ids = load_graphs(base_path)\n",
    "\n",
    "# DataLoader\n",
    "loader = DataLoader(graphs, batch_size=32, shuffle=False)\n",
    "\n",
    "# Compute embeddings\n",
    "embeddings = get_embeddings(loader, model, device)\n",
    "\n",
    "# Organize data for saving\n",
    "data_dict = {'graph': graphs, 'graph_embed': embeddings, 'label': labels, 'input_ids': input_ids}\n",
    "torch.save(data_dict, 'graphs_data.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
